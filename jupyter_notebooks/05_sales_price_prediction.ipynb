{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sales Price Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Fit and evaluate a classification model to predic house sales price.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "outputs/datasets/cleaned/clean_house_price_records.csv\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Train set \n",
    "* Test set\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* Feature importance\n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "* This file and its contents were inspired by and adapted from the Churnometer Walkthrough Project 2 and other lessons from Code Institute.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change working directory\n",
    "\n",
    "We need to change the working directory from its current folder to its parent folder\n",
    "\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs/datasets/cleaned/clean_house_price_records.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Pipeline with all data\n",
    "\n",
    "- ML pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "### Feature Engineering\n",
    "from feature_engine import transformation as vt\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "### Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "### ML algorithms\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from feature_engine.imputation import MeanMedianImputer, CategoricalImputer \n",
    "import pandas as pd\n",
    "\n",
    "selection_method = \"cardinality\"\n",
    "corr_method = \"spearman\"\n",
    "\n",
    "def PipelineOptimization(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"NumericMissingValueImputer\", MeanMedianImputer(imputation_method='median',\n",
    "                                                         variables=['1stFlrSF', 'LotArea', 'GrLivArea', \n",
    "                                                                    'MasVnrArea', 'OpenPorchSF'])),\n",
    "        \n",
    "        (\"CategoricalMissingValueImputer\", CategoricalImputer(imputation_method='frequent',\n",
    "                                                              variables=['BsmtExposure', 'BsmtFinType1', \n",
    "                                                                         'GarageFinish', 'KitchenQual'])),\n",
    "        \n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
    "                                                     variables=['BsmtExposure', 'BsmtFinType1', \n",
    "                                                                'GarageFinish', 'KitchenQual'])),\n",
    "        \n",
    "        (\"NumericLogTransform\", vt.LogTransformer(variables=['1stFlrSF', 'LotArea', 'GrLivArea'])),\n",
    "        \n",
    "        (\"NumericPowerTransform\", vt.PowerTransformer(variables=['MasVnrArea'])),\n",
    "        \n",
    "        (\"NumericYeoJohnsonTransform\", vt.YeoJohnsonTransformer(variables=['OpenPorchSF'])),\n",
    "        \n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "\n",
    "        (\"FinalImputer\", SimpleImputer(strategy=\"mean\")),\n",
    "\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        \n",
    "        (\"model\", model),\n",
    "        \n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Class for Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = PipelineOptimization(self.models[key])\n",
    "\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape,\n",
    "      \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV - Sklearn\n",
    "\n",
    "#### Use standard hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick GridSearch CV - Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top Model Performance: ExtraTreesRegressor achieved the highest average R2 score at 0.82, surpassing the client’s requirement of at least 0.75 for model selection.\n",
    "\n",
    "- Variability Across Models: While ExtraTreesRegressor and LinearRegression performed well with mean scores above 0.80, other models like RandomForestRegressor and XGBRegressor showed lower average R2 scores, particularly XGBRegressor, with an average score of 0.65.\n",
    "\n",
    "- Standard Deviation Insights: The lower standard deviation in models like LinearRegression suggests consistent performance, while models such as GradientBoostingRegressor showed greater variability, indicating more fluctuation in R2 scores across different test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extensive search to the most suitable model\n",
    "\n",
    "In this code, we define a model search for optimizing hyperparameters specifically for the `ExtraTreesRegressor` model. We set up a range of values for each key hyperparameter:\n",
    "\n",
    "- `n_estimators`: Number of trees in the forest.\n",
    "- `max_depth`: Maximum depth of each tree.\n",
    "- `min_samples_split`: Minimum number of samples required to split an internal node.\n",
    "- `min_samples_leaf`: Minimum number of samples required to be at a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"ExtraTreesRegressor\": {\n",
    "        'model__n_estimators': [100, 300, 500],\n",
    "        'model__max_depth': [10, 20, None],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4],\n",
    "    }\n",
    "}\n",
    "\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)\n",
    "\n",
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the best regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "data_cleaning_feat_eng_steps = 6 \n",
    "columns_after_data_cleaning_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                                        .transform(X_train)\n",
    "                                        .columns)\n",
    "\n",
    "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support(\n",
    ")].to_list()\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on: \\n{best_features}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor with Principal Component Analysis\n",
    "\n",
    "potential values for Principal Component n_components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PipelineOptimization(model=LinearRegression())\n",
    "pipeline_pca = Pipeline(pipeline.steps[:8])\n",
    "df_pca = pipeline_pca.fit_transform(df.drop(['SalePrice'],axis=1))\n",
    "\n",
    "print(df_pca.shape,'\\n', type(df_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA separately to the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 17\n",
    "\n",
    "\n",
    "def pca_components_analysis(df_pca, n_components):\n",
    "    pca = PCA(n_components=n_components).fit(df_pca)\n",
    "    x_PCA = pca.transform(df_pca)  # array with transformed PCA\n",
    "\n",
    "    ComponentsList = [\"Component \" + str(number)\n",
    "                      for number in range(n_components)]\n",
    "    dfExplVarRatio = pd.DataFrame(\n",
    "        data=np.round(100 * pca.explained_variance_ratio_, 3),\n",
    "        index=ComponentsList,\n",
    "        columns=['Explained Variance Ratio (%)'])\n",
    "\n",
    "    dfExplVarRatio['Accumulated Variance'] = dfExplVarRatio['Explained Variance Ratio (%)'].cumsum(\n",
    "    )\n",
    "\n",
    "    PercentageOfDataExplained = dfExplVarRatio['Explained Variance Ratio (%)'].sum(\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"* The {n_components} components explain {round(PercentageOfDataExplained,2)}% of the data \\n\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    sns.lineplot(data=dfExplVarRatio,  marker=\"o\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(np.arange(0, 110, 10))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "pca_components_analysis(df_pca=df_pca, n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 9\n",
    "pca_components_analysis(df_pca=df_pca, n_components=n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite ML Pipeline for Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Numerical Variables: Skewness and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "data_path = \"outputs/datasets/cleaned/clean_house_price_records.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "numerical_columns = ['1stFlrSF', 'LotArea', 'GrLivArea', 'GarageArea', 'MasVnrArea']\n",
    "\n",
    "df = df[[col for col in numerical_columns if col in df.columns]]\n",
    "\n",
    "for col in df.columns:\n",
    "    col_skew = skew(df[col].dropna())\n",
    "    print(f\"{col}: Skewness = {col_skew:.2f}\")\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df[col].dropna(), kde=True)\n",
    "    plt.title(f'Distribution of {col} (Skewness = {col_skew:.2f})')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "correlation_matrix = df.corr(method='spearman')\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "plt.title(\"Spearman Correlation Matrix for Numerical Variables\")\n",
    "plt.show()\n",
    "\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline(steps=[('NumericMissingValueImputer',\n",
    "                 MeanMedianImputer(variables=['1stFlrSF', 'LotArea',\n",
    "                                              'GrLivArea', 'MasVnrArea',\n",
    "                                              'OpenPorchSF'])),\n",
    "                ('CategoricalMissingValueImputer',\n",
    "                 CategoricalImputer(imputation_method='frequent',\n",
    "                                    variables=['BsmtExposure', 'BsmtFinType1',\n",
    "                                               'GarageFinish',\n",
    "                                               'KitchenQual'])),\n",
    "                ('OrdinalCategoricalEncoder',\n",
    "                 OrdinalEncoder(encoding_meth...\n",
    "                 PowerTransformer(variables=['MasVnrArea'])),\n",
    "                ('NumericYeoJohnsonTransform',\n",
    "                 YeoJohnsonTransformer(variables=['OpenPorchSF'])),\n",
    "                ('feat_scaling', StandardScaler()),\n",
    "                ('FinalImputer', SimpleImputer()),\n",
    "                ('feat_selection',\n",
    "                 SelectFromModel(estimator=ExtraTreesRegressor(random_state=0))),\n",
    "                ('model',\n",
    "                 ExtraTreesRegressor(max_depth=20, min_samples_leaf=2,\n",
    "                                     min_samples_split=10, n_estimators=300,\n",
    "                                     random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PipelineOptimization(model, n_components=7):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"NumericMissingValueImputer\", MeanMedianImputer(variables=['1stFlrSF', 'LotArea', 'GrLivArea', 'MasVnrArea', 'OpenPorchSF'])),\n",
    "        \n",
    "        (\"CategoricalMissingValueImputer\", CategoricalImputer(imputation_method='frequent', \n",
    "                                                              variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'])),\n",
    "        \n",
    "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary', \n",
    "                                                     variables=['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual'])),\n",
    "        \n",
    "        (\"NumericLogTransform\", LogTransformer(variables=['1stFlrSF', 'LotArea', 'GrLivArea'])),\n",
    "        \n",
    "        (\"NumericPowerTransform\", PowerTransformer(variables=['GarageArea', 'MasVnrArea'])),\n",
    "        \n",
    "        (\"NumericYeoJohnsonTransform\", YeoJohnsonTransformer(variables=['OpenPorchSF'])),\n",
    "        \n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "        \n",
    "        (\"PCA\", PCA(n_components=n_components, random_state=0)),\n",
    "        \n",
    "        (\"FinalImputer\", SimpleImputer()),\n",
    "        \n",
    "        (\"feat_selection\", SelectFromModel(estimator=ExtraTreesRegressor(random_state=0))),\n",
    "        \n",
    "        (\"model\", model),\n",
    "    ])\n",
    "    \n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV – Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "    \"GradientBoostingRegressor\": {},\n",
    "    \"XGBRegressor\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick optimisation search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.transformation import LogTransformer, PowerTransformer, YeoJohnsonTransformer\n",
    "\n",
    "quick_search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "quick_search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extensive search on the most suitable model to find the best hyperparameter configuration\n",
    "\n",
    "Extensive GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"ExtraTreesRegressor\": {\n",
    "        'model__n_estimators': [100, 300, 500, 700],\n",
    "        'model__max_depth': [10, 20, None],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4],\n",
    "    }\n",
    "}\n",
    "\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the best regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = X_train.columns.to_list()\n",
    "\n",
    "important_features = ['Feature_17', 'Feature_10', 'Feature_18', 'Feature_19', 'Feature_20']\n",
    "\n",
    "important_features_mapped = {feature: original_features[int(feature.split('_')[1])] for feature in important_features}\n",
    "\n",
    "print(\"Mapping of important features to original variable names:\")\n",
    "for placeholder, original_name in important_features_mapped.items():\n",
    "    print(f\"{placeholder} corresponds to original feature '{original_name}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a pipeline that excludes PCA and feature selection to retain all features\n",
    "pipeline_full_features = Pipeline([\n",
    "    (name, step) for name, step in best_regressor_pipeline.steps[:-1]\n",
    "    if name not in ['PCA', 'feat_selection']\n",
    "])\n",
    "\n",
    "# Transform the data up to the last step without PCA and selection\n",
    "X_train_full_features = pipeline_full_features.fit_transform(X_train, y_train)\n",
    "\n",
    "# Fit ExtraTreesRegressor on the transformed data without dimensionality reduction\n",
    "model_no_reduction = ExtraTreesRegressor(random_state=0)\n",
    "model_no_reduction.fit(X_train_full_features, y_train)\n",
    "\n",
    "# Mapping original feature names based on the order in X_train\n",
    "original_feature_names = X_train.columns.to_list()\n",
    "\n",
    "# Replace placeholder names with original feature names\n",
    "df_feature_importance = pd.DataFrame({\n",
    "    'Feature': original_feature_names,  # Use original feature names here\n",
    "    'Importance': model_no_reduction.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select and display the top 5 important features\n",
    "top_n_features = 5\n",
    "df_top_features = df_feature_importance.head(top_n_features)\n",
    "\n",
    "print(f\"* The top {top_n_features} most important features in the model are:\\n{df_top_features['Feature'].tolist()}\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=df_top_features)\n",
    "plt.title(f\"Top {top_n_features} Feature Importance for ExtraTreesRegressor\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Evaluation Summary:\\n\")\n",
    "    print(\"* Training Data Evaluation\")\n",
    "    assess_performance(X_train, y_train, pipeline)\n",
    "    print(\"* Testing Data Evaluation\")\n",
    "    assess_performance(X_test, y_test, pipeline)\n",
    "\n",
    "def assess_performance(X, y, pipeline):\n",
    "    predictions = pipeline.predict(X)\n",
    "    print(f'R2 Score: {r2_score(y, predictions):.3f}')\n",
    "    print(f'Mean Absolute Error (MAE): {mean_absolute_error(y, predictions):.3f}')\n",
    "    print(f'Mean Squared Error (MSE): {mean_squared_error(y, predictions):.3f}')\n",
    "    print(f'Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y, predictions)):.3f}')\n",
    "    print(\"\\n\")\n",
    "\n",
    "def plot_model_evaluation(X_train, y_train, X_test, y_test, pipeline, alpha=0.5):\n",
    "    train_preds = pipeline.predict(X_train)\n",
    "    test_preds = pipeline.predict(X_test)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    sns.scatterplot(x=y_train, y=train_preds, alpha=alpha, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual Values\")\n",
    "    axes[0].set_ylabel(\"Predicted Values\")\n",
    "    axes[0].set_title(\"Train Data Performance\")\n",
    "    \n",
    "    sns.scatterplot(x=y_test, y=test_preds, alpha=alpha, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual Values\")\n",
    "    axes[1].set_ylabel(\"Predicted Values\")\n",
    "    axes[1].set_title(\"Test Data Performance\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test, best_regressor_pipeline)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Output Directory for Pipeline Results\n",
    "\n",
    "This code snippet creates a versioned directory structure to store output files, such as models, datasets, and visualizations generated by the machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "version = \"v1\"  \n",
    "output_dir = f\"outputs/ml_pipeline/predict_saleprice/{version}\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Output directory created at: {output_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kolumner som användes för träning:\")\n",
    "print(price_pipeline.feature_names_in_)\n",
    "print(f\"Antal kolumner: {len(price_pipeline.feature_names_in_)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Training and Test Datasets\n",
    "\n",
    "This code saves the training and test datasets (`X_train`, `y_train`, `X_test`, `y_test`) as CSV files in the designated output directory. Storing these files allows for easy access to the train-test split in future analysis without recreating it each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Train data\n",
    "X_train.to_csv(f\"{output_dir}/X_train.csv\", index=False)\n",
    "y_train.to_csv(f\"{output_dir}/y_train.csv\", index=False)\n",
    "\n",
    "# Save Test data\n",
    "X_test.to_csv(f\"{output_dir}/X_test.csv\", index=False)\n",
    "y_test.to_csv(f\"{output_dir}/y_test.csv\", index=False)\n",
    "\n",
    "print(\"Training and test datasets saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Best Model Pipeline\n",
    "\n",
    "This code saves the trained model pipeline (`best_regressor_pipeline`) as a `.pkl` file in the output directory. Storing the pipeline allows for future use of the trained model for predictions without the need for retraining. This step is essential for model deployment and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_filename = f\"{output_dir}/best_regressor_pipeline.pkl\"\n",
    "joblib.dump(value=best_regressor_pipeline, filename=model_filename)\n",
    "\n",
    "print(\"Best model pipeline saved successfully as:\", model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Visualize Feature Importance\n",
    "\n",
    "This code saves the feature importance values from the trained model into a CSV file and generates a bar plot displaying each feature's importance. The plot is saved as a PNG image in the output directory. This step helps to understand which features have the most influence on the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_filename = f\"{output_dir}/feature_importance.csv\"\n",
    "df_feature_importance.to_csv(feature_importance_filename, index=False)\n",
    "print(\"Feature importance saved successfully as:\", feature_importance_filename)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=df_feature_importance.sort_values(by=\"Importance\", ascending=False))\n",
    "plt.title(\"Feature Importance for Best Model\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "\n",
    "feature_importance_plot_filename = f\"{output_dir}/feature_importance.png\"\n",
    "plt.savefig(feature_importance_plot_filename, bbox_inches='tight')\n",
    "print(\"Feature importance plot saved successfully as:\", feature_importance_plot_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize and Save Model Performance\n",
    "\n",
    "This code creates scatter plots comparing actual and predicted sale prices for both the training and test sets. A red line represents the ideal fit where predictions equal actual values, providing a visual benchmark for model accuracy. The plots are saved as a PNG image in the output directory, offering a quick overview of the model's predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = best_regressor_pipeline.predict(X_train)\n",
    "pred_test = best_regressor_pipeline.predict(X_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha_scatter = 0.5\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "axes[0].set_xlabel(\"Actual Sale Price\")\n",
    "axes[0].set_ylabel(\"Predicted Sale Price\")\n",
    "axes[0].set_title(\"Train Set Performance\")\n",
    "\n",
    "sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "axes[1].set_xlabel(\"Actual Sale Price\")\n",
    "axes[1].set_ylabel(\"Predicted Sale Price\")\n",
    "axes[1].set_title(\"Test Set Performance\")\n",
    "\n",
    "performance_plot_filename = f\"{output_dir}/regression_evaluation_plots.png\"\n",
    "plt.savefig(performance_plot_filename, bbox_inches='tight')\n",
    "print(\"Model performance plot saved successfully as:\", performance_plot_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The model developed for predicting house sale prices has successfully met and exceeded the business requirement of achieving an R2 score of 0.75 or higher on test data. Key findings and outcomes include:\n",
    "\n",
    "1. **Model Performance**:\n",
    "   - **Train Set**: The model achieved an R2 score of 0.849, indicating a strong fit to the training data.\n",
    "   - **Test Set**: The model achieved an R2 score of 0.804, meeting the business requirement and demonstrating good generalization to new data.\n",
    "\n",
    "2. **Feature Importance**:\n",
    "   - The model's feature importance analysis highlighted several key variables that significantly impact sale price predictions, including `1stFlrSF`, `GarageArea`, and `GrLivArea`. This insight is valuable for understanding which factors are most influential in determining house prices.\n",
    "\n",
    "3. **Residual Analysis**:\n",
    "   - Visualization of actual vs. predicted sale prices on both the training and test sets shows a generally strong alignment along the ideal line, especially for properties within a certain price range. However, some variance is observed, suggesting possible improvements in capturing extreme values.\n",
    "\n",
    "4. **Model Deployment Readiness**:\n",
    "   - The entire pipeline, including data processing and model training, has been saved as reusable files, ensuring that the model can be loaded and used for predictions without retraining. This makes the model deployment-ready and easy to integrate into a larger application.\n",
    "\n",
    "Overall, the model meets the business requirements and offers a reliable tool for predicting house sale prices. Future work could focus on further feature engineering and hyperparameter tuning to enhance performance for higher-priced properties, but the current model is well-suited for production use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
